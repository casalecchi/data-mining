{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separação de arquivos para treino e teste do modelo\n",
    "\n",
    "* Rodar em menos tempo - apenas dois arquivos para o treino ~ aproximadamente 1 hora.\n",
    "* Um arquivo para o teste e ter métricas.\n",
    "* Um arquivo de resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = [\n",
    "    \"../data/bus/final/2024-05-17/2024-05-17_09.json\",\n",
    "    \"../data/bus/final/2024-05-17/2024-05-17_10.json\",\n",
    "]\n",
    "\n",
    "test_files = [\n",
    "    \"../data/bus/final/2024-05-17/teste-2024-05-17_11.json\",\n",
    "]\n",
    "\n",
    "answer_files = [\n",
    "    \"../data/bus/teste/2024-05-15/resposta-2024-05-15_08.json\"\n",
    "]\n",
    "\n",
    "train_first = pd.read_json(train_files[0], encoding='latin-1')\n",
    "train_second = pd.read_json(train_files[1], encoding='latin-1')\n",
    "\n",
    "train = pd.concat([train_first, train_second])\n",
    "test = pd.read_json(test_files[0], encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamento das colunas e linhas de ônibus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [\n",
    "    '483', '864', '639', '3', '309', '774', '629', '371', '397', '100', '838', \n",
    "    '315', '624', '388', '918', '665', '328', '497', '878', '355', '138', '606', \n",
    "    '457', '550', '803', '917', '638', '2336', '399', '298', '867', '553', '565', \n",
    "    '422', '756', '186012003', '292', '554', '634', '232', '415', '2803', '324', \n",
    "    '852', '557', '759', '343', '779', '905', '108'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['latitude'] = train['latitude'].str.replace(',', '.').astype(float)\n",
    "train['longitude'] = train['longitude'].str.replace(',', '.').astype(float)\n",
    "train['linha'] = train['linha'].astype(str)\n",
    "train = train[train['linha'].isin(lines)]\n",
    "test['linha'] = test['linha'].astype(str)\n",
    "test['latitude'] = test['latitude'].str.replace(',', '.').astype(float)\n",
    "test['longitude'] = test['longitude'].str.replace(',', '.').astype(float)\n",
    "test = test[test['linha'].isin(lines)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_two = train.groupby(['ordem', 'linha']).tail(2).reset_index(drop=True)\n",
    "size = last_two.groupby(['ordem', 'linha']).size()\n",
    "to_duplicate = size[size == 1].index\n",
    "duplicats = last_two.set_index(['ordem', 'linha']).loc[to_duplicate].reset_index()\n",
    "last_two = pd.concat([last_two, duplicats]).sort_values(['ordem', 'linha'])\n",
    "# Deixar apenas algumas colunas\n",
    "last_two = last_two[['ordem','linha','latitude','longitude','datahoraservidor']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntar DataFrame de teste com o de treino modificado\n",
    "join_df = pd.merge(test, last_two, on=['ordem','linha'], how='inner', suffixes=('_test', '_last_two'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conectar ao Banco de Dados PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_url = \"postgresql://postgres:camila@localhost:5432/postgres\"\n",
    "engine = create_engine(database_url, client_encoding='latin-1')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(connection, linha, lat1, lon1, lat2, lon2, last_date, prediction_lat, prediction_lon):\n",
    "    query = \"\"\"\n",
    "    WITH initial_similar_points AS (\n",
    "        SELECT time_ranking,\n",
    "               ordem,\n",
    "               linha,\n",
    "               x,\n",
    "               y,\n",
    "               datahoraservidor\n",
    "        FROM vw_buses_order\n",
    "        WHERE linha = :linha\n",
    "        AND x = width_bucket(:lon1, -43.726090, -42.951470, 1587)\n",
    "        AND y = width_bucket(:lat1, -23.170790, -22.546410, 1389)\n",
    "        AND (\n",
    "                (datahoraservidor >= TO_TIMESTAMP(:last_date) - interval '7 day' - interval '2 hour'  \n",
    "                AND datahoraservidor < TO_TIMESTAMP(:last_date) - interval '7 day' + interval '2 hour') \n",
    "                OR \n",
    "                (datahoraservidor >= TO_TIMESTAMP(:last_date) - interval '14 day' - interval '2 hour'  \n",
    "                AND datahoraservidor < TO_TIMESTAMP(:last_date) - interval '14 day' + interval '2 hour')\n",
    "                OR \n",
    "                (datahoraservidor >= TO_TIMESTAMP(:last_date) - interval '21 day' - interval '2 hour'  \n",
    "                AND datahoraservidor < TO_TIMESTAMP(:last_date) - interval '21 day' + interval '2 hour')\n",
    "            )\n",
    "        AND time_ranking > 1\n",
    "        LIMIT 10\n",
    "    ), anterior_points AS (\n",
    "        SELECT DISTINCT ON (time_ranking, ordem, linha) \n",
    "            time_ranking,\n",
    "            ordem,\n",
    "            linha,\n",
    "            x,\n",
    "            y,\n",
    "            datahoraservidor\n",
    "        FROM vw_buses_order\n",
    "        WHERE (ordem, linha, time_ranking) IN (\n",
    "            SELECT ordem, linha, time_ranking - 1\n",
    "            FROM initial_similar_points\n",
    "            )\n",
    "    ), direction_points AS (\n",
    "         SELECT \n",
    "            sp.ordem,\n",
    "            sp.datahoraservidor\n",
    "        FROM initial_similar_points sp\n",
    "        INNER JOIN anterior_points ap\n",
    "            ON sp.ordem = ap.ordem\n",
    "            AND sp.linha = ap.linha\n",
    "            AND sp.time_ranking = ap.time_ranking + 1\n",
    "        WHERE ((ap.x - sp.x) * (:lon2 - :lon1) + (ap.y - sp.y) * (:lat2 - :lat1)) >= 0\n",
    "    ), first_future_points AS (\n",
    "        SELECT \n",
    "            vo.ordem,\n",
    "            vo.datahoraservidor - dp.datahoraservidor AS time_diff\n",
    "        FROM (\n",
    "                SELECT \n",
    "                          ordem,\n",
    "                          linha,\n",
    "                          x,\n",
    "                          y,\n",
    "                          datahoraservidor\n",
    "                FROM vw_buses_order\n",
    "                WHERE linha = :linha\n",
    "                AND ordem IN (SELECT DISTINCT ordem FROM direction_points)\n",
    "             ) vo\n",
    "        INNER JOIN direction_points dp\n",
    "            ON vo.ordem = dp.ordem\n",
    "            AND vo.datahoraservidor > dp.datahoraservidor\n",
    "            AND vo.datahoraservidor < dp.datahoraservidor + interval '1 hour' + interval '20 minutes'\n",
    "        WHERE vo.x < width_bucket(:prediction_lon, -43.726090, -42.951470, 1587) + 2\n",
    "        AND vo.x > width_bucket(:prediction_lon, -43.726090, -42.951470, 1587) - 2\n",
    "        AND vo.y < width_bucket(:prediction_lat, -23.170790, -22.546410, 1389) + 2\n",
    "        AND vo.y > width_bucket(:prediction_lat, -23.170790, -22.546410, 1389) - 2\n",
    "    ), selected_future_points AS (\n",
    "        SELECT time_diff\n",
    "        FROM first_future_points\n",
    "    )\n",
    "    SELECT \n",
    "        percentile_cont(0.5) WITHIN GROUP (ORDER BY time_diff) AS median_time_diff\n",
    "    FROM selected_future_points;\n",
    "    \"\"\"\n",
    "    \n",
    "    params = {\n",
    "        'linha': linha,\n",
    "        'lat1': lat1,\n",
    "        'lon1': lon1,\n",
    "        'lat2': lat2,\n",
    "        'lon2': lon2,\n",
    "        'last_date': str(last_date),\n",
    "        'prediction_lat': prediction_lat,\n",
    "        'prediction_lon': prediction_lon\n",
    "    }\n",
    "    \n",
    "    \n",
    "    result = connection.execute(text(query), params)\n",
    "    row = result.fetchone()\n",
    "        \n",
    "    return row[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2c/rr_qb8ln101dbc1k0yyw601r0000gn/T/ipykernel_35872/1119380942.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i in tqdm_notebook(range(0, len(join_df)- 1, 2)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e059de4f7c6426f985173ea658d307d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/167052 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "median_time_diff_list = []\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    for i in tqdm_notebook(range(0, len(join_df)- 1, 2)):\n",
    "        row1 = join_df.iloc[i + 1]\n",
    "        row2 = join_df.iloc[i]\n",
    "        median_time_diff = execute_query(\n",
    "            connection,\n",
    "            row1['linha'], \n",
    "            row1['latitude_last_two'], \n",
    "            row1['longitude_last_two'], \n",
    "            row2['latitude_last_two'], \n",
    "            row2['longitude_last_two'], \n",
    "            row1['datahoraservidor']/1000,\n",
    "            row1['latitude_test'],\n",
    "            row1['longitude_test']\n",
    "        )\n",
    "\n",
    "        median_time_diff_list.extend([median_time_diff, median_time_diff])\n",
    "\n",
    "join_df['median_time_diff'] = median_time_diff_list\n",
    "prediction = join_df[['id','datahoraservidor', 'median_time_diff']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  0.000000\n",
       "datahoraservidor    0.000000\n",
       "median_time_diff    4.323205\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(prediction.isnull().sum()/len(prediction)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processamento de dados dos resultados\n",
    "\n",
    "* Tirar duplicatas\n",
    "* Substituir valores que não existem pelo tempo anterior mais 30 minutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2c/rr_qb8ln101dbc1k0yyw601r0000gn/T/ipykernel_35872/2691559552.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  prediction['real_time'] =  prediction['datahoraservidor'] + prediction['median_time_diff'].dt.total_seconds() * 1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>real_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>736178940</td>\n",
       "      <td>1715954340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8162198327405</td>\n",
       "      <td>1715952524000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11893461699572</td>\n",
       "      <td>1715954340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19153973236932</td>\n",
       "      <td>1715952723000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19945978699202</td>\n",
       "      <td>1715953027000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id      real_time\n",
       "1       736178940  1715954340000\n",
       "3   8162198327405  1715952524000\n",
       "5  11893461699572  1715954340000\n",
       "7  19153973236932  1715952723000\n",
       "9  19945978699202  1715953027000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction['real_time'] =  prediction['datahoraservidor'] + prediction['median_time_diff'].dt.total_seconds() * 1000\n",
    "prediction = prediction.iloc[1::2]\n",
    "prediction['real_time'] = prediction['real_time'].fillna(prediction['datahoraservidor'].max() + 30 * 60 * 1000)\n",
    "prediction['real_time'] = prediction['real_time'].astype('Int64')\n",
    "prediction = prediction[['id','real_time']]\n",
    "prediction.drop_duplicates(inplace=True)\n",
    "prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction['id'] = prediction['id'].astype('Int64')\n",
    "previsoes = prediction.values.tolist()\n",
    "\n",
    "match = re.search(r'teste-(\\d{4}-\\d{2}-\\d{2})_(\\d{2})', test_files[0])\n",
    "date_part = match.group(1)\n",
    "hour_part = match.group(2)\n",
    "datahora = f\"{date_part} {hour_part}:00:00\"\n",
    "\n",
    "output = {\n",
    "    \"aluno\": \"Felipe Vilela Magalhães Casalecchi\",\n",
    "    \"datahora\": datahora,\n",
    "    \"previsoes\": [[str(item) if isinstance(item, pd.Int64Dtype) else item for item in row] for row in previsoes],\n",
    "    \"senha\": \"dataMining\"\n",
    "}\n",
    "\n",
    "output_json = json.dumps(output, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON salvo em 24-05-17_11_answer.json\n"
     ]
    }
   ],
   "source": [
    "output_filename = test_files[0][37:48] + \"_answer.json\"\n",
    "with open(output_filename, \"w\") as json_file:\n",
    "    json_file.write(output_json)\n",
    "\n",
    "print(f\"JSON salvo em {output_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mandar resposta para Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST bem-sucedido!\n",
      "Resposta do servidor:\n",
      "{'msg': 'Problemas!', 'arquivo teste': 'teste-2024-05-17_11.json', 'rmse': 781.9322463069116, 'ids não encontrados': 0, 'ids testados': 167052, 'total na tabela': 168655}\n"
     ]
    }
   ],
   "source": [
    "url = 'https://barra.cos.ufrj.br:443/rest/rpc/avalia'\n",
    "headers = {\n",
    "    'accept': 'application/json',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "response = requests.post(url, headers=headers, data=output_json)\n",
    "if response.status_code == 200:\n",
    "    print(\"POST bem-sucedido!\")\n",
    "    print(\"Resposta do servidor:\")\n",
    "    print(response.json())\n",
    "else:\n",
    "    print(f\"Falha no POST: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmt-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
